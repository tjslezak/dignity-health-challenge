{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning exercise\n",
    "### TJ Slezak\n",
    "\n",
    "Design and create a machine learning model that classifies a name as either male or female based on the characteristics of the name. Write up a report with screenshots in a text document or Jupyter notebook that describes the following:\n",
    "\n",
    "•\tthe input data and its quality\n",
    "\n",
    "•\tany data exploration and any interesting insights\n",
    "\n",
    "•\tany preprocessing or cleaning of the data that was needed, including how you chose to label the data (i.e., how you labeled a name male or female as the ground truth for the model)\n",
    "\n",
    "•\tthe features used by your model and why you chose them\n",
    "\n",
    "•\tyour selection of machine learning algorithm and why it was chosen\n",
    "\n",
    "•\tthe accuracy of your model and any relevant metrics that describe model performance\n",
    "\n",
    "•\tany model parameter tuning used to improve performance\n",
    "\n",
    "•\tany relevant discussion, model interpretation, future steps, or further exploration needed\n",
    "\n",
    "In addition, prepare a short slideshow presentation (~10 min.) of an overview of the machine learning exercise. You will present this to the analytics team.\n",
    "There are no restrictions on the classification model that you use; however, be sure to keep in mind your ability to adequately explain and interpret the results.\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/names_df.csv')\n",
    "df['Name'] = df.Name.str.strip('--')\n",
    "df['Number'] = df.Number.str.strip('L00').astype(np.int)\n",
    "df['Year'] = df.Year.str.strip('Y').astype(np.int)\n",
    "idx = df[df.Year == 88].index[0]\n",
    "df.at[idx, 'Year'] = 1888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = df.Sex.apply(lambda x: 0 if x=='F' else 1)\n",
    "df.drop(columns=['Year'], inplace=True)\n",
    "groups = df.groupby(['Sex', 'Name'], as_index=False).sum()\n",
    "group = df.groupby(['Name']).sum()\n",
    "group.drop(columns='Sex', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of names by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aaban</th>\n",
       "      <td>107</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aabha</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aabid</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aabir</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aabriella</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Number   Male  Female\n",
       "Name                            \n",
       "Aaban         107  107.0     0.0\n",
       "Aabha          35    0.0    35.0\n",
       "Aabid          10   10.0     0.0\n",
       "Aabir           5    5.0     0.0\n",
       "Aabriella      32    0.0    32.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male = groups[groups.Sex==1].drop(columns=['Sex']).set_index('Name')\n",
    "fem = groups[groups.Sex==0].drop(columns=['Sex']).set_index('Name')\n",
    "\n",
    "for name, row in group.iterrows():\n",
    "    total = row.Number\n",
    "    try: \n",
    "        n_male = male.at[name, 'Number']\n",
    "        group.loc[name, 'Male'] = int(n_male)\n",
    "    except:\n",
    "        group.loc[name, 'Male'] = 0\n",
    "        \n",
    "group['Female'] = group.Number - group.Male\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code below shows the n-grams for Male names and their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " a        3682\n",
       " aa        157\n",
       " aab         3\n",
       " aaba        1\n",
       " aaban       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_vect = CountVectorizer(analyzer='char_wb', ngram_range=(2,8))\n",
    "male_counts = male_vect.fit_transform(male.index)\n",
    "male_counts = male_counts.sum(axis=0).A1\n",
    "m_vocab = male_vect.get_feature_names()\n",
    "mdf = pd.Series(male_counts, index=m_vocab)\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code below shows the n-grams for Male names and their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " a        7604\n",
       " aa        257\n",
       " aab         2\n",
       " aabh        1\n",
       " aabha       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fem_vect = CountVectorizer(analyzer='char_wb', ngram_range=(2,8))\n",
    "fem_counts = fem_vect.fit_transform(fem.index)\n",
    "fem_counts = fem_counts.sum(axis=0).A1\n",
    "f_vocab = fem_vect.get_feature_names()\n",
    "fdf = pd.Series(fem_counts, index=f_vocab)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab for all n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' a', ' aa', ' aab', ' aaba', ' aaban', ' aaban ', ' aabh', ' aabha', ' aabha ', ' aabi', ' aabid', ' aabid ', ' aabir', ' aabir ', ' aabr', ' aabri', ' aabrie', ' aabriel', ' aad', ' aada', ' aada ', ' aadam', ' aadam ', ' aadan', ' aadan ', ' aadar', ' aadars', ' aadarsh', ' aade', ' aaden', ' aaden ', ' aades', ' aadesh', ' aadesh ', ' aadh', ' aadha', ' aadhav', ' aadhav ', ' aadhava', ' aadhi', ' aadhi ', ' aadhir', ' aadhira', ' aadhv', ' aadhvi', ' aadhvik', ' aadhy', ' aadhya', ' aadhya ', ' aadhyan']\n"
     ]
    }
   ],
   "source": [
    "vocab = set(m_vocab) | set(f_vocab)\n",
    "vocab = sorted(vocab)\n",
    "print(vocab[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "for v in vocab:\n",
    "    try:\n",
    "        m = mdf.loc[v]\n",
    "    except:\n",
    "        m = 0\n",
    "    try:\n",
    "        f = fdf.loc[v]\n",
    "    except:\n",
    "        f = 0\n",
    "        \n",
    "    d[v] = [m, f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of sex by n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>p_male</th>\n",
       "      <th>p_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3682</td>\n",
       "      <td>7604</td>\n",
       "      <td>0.326245</td>\n",
       "      <td>0.673755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>157</td>\n",
       "      <td>257</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.620773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aab</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaba</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaban</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Male  Female    p_male  p_female\n",
       " a      3682    7604  0.326245  0.673755\n",
       " aa      157     257  0.379227  0.620773\n",
       " aab       3       2  0.600000  0.400000\n",
       " aaba      1       0  1.000000  0.000000\n",
       " aaban     1       0  1.000000  0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.DataFrame.from_dict(d, orient='index', columns=['Male', 'Female'])\n",
    "p['p_male'] = p.Male / (p.Male + p.Female)\n",
    "p['p_female'] = p.Female / (p.Male + p.Female)\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute priors (the probability a name will be Female or Male if selected randomly, regardless of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5914239620921043, 0.40857603790789565]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = len(df.Sex)\n",
    "M = df.Sex.sum()\n",
    "F = T - M\n",
    "priors = [F/T, M/T]\n",
    "priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find minimum and maximum length of names in dataset (bounds for n-gram selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Name.str.len().min(), df.Name.str.len().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate response and features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Sex\n",
    "X = df.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split of 80/20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Simple tokenizer.\n",
    "Name Features: \n",
    "1. First letter\n",
    "2. Last letter\n",
    "3. Last two letters\n",
    "4. all other letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(name):\n",
    "    features = list()\n",
    "    features.append(name[0])\n",
    "    features.append(name[-1].lower())\n",
    "    features.append(name[-2:].lower())\n",
    "    features.extend(name[1:-2].lower().split())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 's', 'as', 'hom']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Thomas'\n",
    "tokenizer(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.8 s, sys: 1.23 s, total: 45 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = CountVectorizer(tokenizer=tokenizer, lowercase=False)\n",
    "X_train_counts = vect.fit_transform(X_train)\n",
    "\n",
    "mnb = MultinomialNB(alpha=0.001).fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = vect.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(mnb, X_train_counts, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8229831 , 0.8227493 , 0.82398976, 0.82451469, 0.82294298,\n",
       "       0.82350802, 0.8243783 , 0.822917  , 0.82287154, 0.8234744 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240109317725423"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = mnb.score(X_test_counts, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.1 s, sys: 1.14 s, total: 45.3 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = CountVectorizer(tokenizer=tokenizer, lowercase=False)\n",
    "X_train_counts = vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_counts = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "mnb = MultinomialNB(alpha=0.001).fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = vect.transform(X_test)\n",
    "X_test_counts = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "cv_scores = cross_val_score(mnb, X_train_counts, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82739943, 0.82681492, 0.8270747 , 0.8281387 , 0.82689822,\n",
       "       0.827775  , 0.82690472, 0.82715151, 0.82653452, 0.82662432])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8270867917273915"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = mnb.score(X_test_counts, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_last(name):\n",
    "    nam = name[:-1]\n",
    "    e = name[-1:].upper()\n",
    "    return nam + e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 8.83 s, total: 1min 54s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(model_mnb, X_train_counts, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8927969282966126, 0.8930034567635445, 0.8929422690991278)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model_mnb.score(X_test_counts, y_test)\n",
    "\n",
    "score, np.mean(cv_scores), np.median(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 9.09 s, total: 1min 57s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores2 = cross_val_score(model_mnb, X_train_counts, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8931840086456604, 0.8932658399811044, 0.8932312808089731)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = model_mnb.score(X_test_counts, y_test)\n",
    "\n",
    "score2, np.mean(cv_scores2), np.median(cv_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 s, sys: 1.58 s, total: 44.8 s\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mnb_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))),\n",
    "    ('clf', MultinomialNB(alpha=0.001)),\n",
    "])\n",
    "\n",
    "mnb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931840086456604"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model_mnb.score(X_test_counts, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 10), preprocessor=None, stop_words=None,\n",
       "        ...ear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_pipe2 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha=0.001)),\n",
    "])\n",
    "\n",
    "mnb_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8951427910831236"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_pipe2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49min 41s, sys: 4.19 s, total: 49min 45s\n",
      "Wall time: 47min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logrcv_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))),\n",
    "    ('logrCV', LogisticRegressionCV(cv=5, random_state=11, fit_intercept=False, max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006164709183156"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrcv_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 16s, sys: 6.79 s, total: 12min 23s\n",
      "Wall time: 17min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logrcv_pipe2 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('logrCV', LogisticRegressionCV(cv=5, random_state=11, fit_intercept=False, max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006970044137551"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrcv_pipe2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 57s, sys: 4.65 s, total: 32min 1s\n",
      "Wall time: 45min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logrcv_pipe3 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('logrCV', LogisticRegressionCV(cv=5, random_state=11, fit_intercept=True, max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006736237215308"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrcv_pipe3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 59s, sys: 6.77 s, total: 11min 6s\n",
      "Wall time: 31min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logrcv_pipe4 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('logrCV', LogisticRegressionCV(cv=10, random_state=11, fit_intercept=False, max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006866129949888"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrcv_pipe4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 9s, sys: 6.76 s, total: 13min 16s\n",
      "Wall time: 19min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logrcv_pipe5 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,12))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('logrCV', LogisticRegressionCV(cv=5, random_state=11, fit_intercept=False, max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006840151402972"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrcv_pipe5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 47s, sys: 5.89 s, total: 11min 53s\n",
      "Wall time: 19min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logrcv_pipe6 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,15))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('logrCV', LogisticRegressionCV(cv=5, random_state=11, fit_intercept=False, max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006918087043719"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrcv_pipe6.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877882644512162"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2,10))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train)\n",
    "\n",
    "model_gnb = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test)\n",
    "\n",
    "model_gnb.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model - Character Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6690333122907103"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(1,1))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "\n",
    "model_mnb.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1539732x763325 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 46601657 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(cwb_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864589422055267"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2,2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "\n",
    "model_mnb.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' a', ' b', ' c', ' d', ' e', ' f', ' g', ' h', ' i', ' j', ' k', ' l', ' m', ' n', ' o', ' p', ' q', ' r', ' s', ' t', ' u', ' v', ' w', ' x', ' y', ' z', 'a ', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'aj', 'ak', 'al', 'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au', 'av', 'aw', 'ax', 'ay', 'az', 'b ', 'ba', 'bb', 'bc', 'bd', 'be', 'bg', 'bh', 'bi', 'bj', 'bl', 'bm', 'bn', 'bo', 'br', 'bs', 'bt', 'bu', 'bw', 'by', 'c ', 'ca', 'cb', 'cc', 'cd', 'ce', 'cg', 'ch', 'ci', 'cj', 'ck', 'cl', 'cm', 'cn', 'co', 'cp', 'cq', 'cr', 'cs', 'ct', 'cu', 'cx', 'cy', 'cz', 'd ', 'da', 'db']\n"
     ]
    }
   ],
   "source": [
    "print(cwb_vectorizer.get_feature_names()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8870738544110274"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "\n",
    "model_mnb.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8887624599605646"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "\n",
    "model_mnb.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8927969282966126"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "\n",
    "model_mnb.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931840086456604"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "\n",
    "model_mnb.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7537207773820379"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(1,2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8053063779930534"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(1,3))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8663975289206174"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(1,4))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.8391668160433114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400007273993136"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,3))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8671223303795725"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,4))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.843866335180408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8816027724305269"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,5))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885884036962276"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,6))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915525558993384"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,7))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8925449363915279"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.8925449363915279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963300106771828"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.01).fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.8925449363915279  alpha = 1.0\n",
    "#0.8963300106771828  alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896348195660024"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.8925449363915279  alpha = 1.0\n",
    "#0.896091008045556   alpha = 0.1\n",
    "#0.8963300106771828  alpha = 0.01\n",
    "#0.896348195660024   alpha = 0.001\n",
    "#0.8962494771817433   alpha = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89362304608854"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,14))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "#X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_counts, y_test)\n",
    "#0.8925449363915279  alpha = 1.0\n",
    "#0.896091008045556   alpha = 0.1\n",
    "#0.8963300106771828  alpha = 0.01\n",
    "#0.896348195660024   alpha = 0.001\n",
    "#0.8965768068728843  ngram_range=(2,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963559892240988"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.8925449363915279  alpha = 1.0\n",
    "#0.896091008045556   alpha = 0.1\n",
    "#0.8963300106771828  alpha = 0.01\n",
    "#0.896348195660024   alpha = 0.001\n",
    "#0.8965768068728843  ngram_range=(2,14)\n",
    "#0.893591871832241   No tfidf\n",
    "###0.8973197933146807 ngram_range=(2,10)\n",
    "#0.8965794047275759 ngram_range=(2,12), smooth_idf=False\n",
    "#0.8965222519243609 ngram_range=(2,10), smooth_idf=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([910303., 629429.])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mnb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8965170562149777"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.001).fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.8925449363915279  alpha = 1.0\n",
    "#0.896091008045556   alpha = 0.1\n",
    "#0.8963300106771828  alpha = 0.01\n",
    "#0.896348195660024   alpha = 0.001\n",
    "#0.896296238566192   alpha = 0.0001\n",
    "#0.8962494771817433  alpha = 0.00001\n",
    "#0.8964936755227533  ngram_range=(2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896091008045556"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB(alpha=0.1).fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)\n",
    "#0.8925449363915279  alpha = 1.0\n",
    "#0.8963300106771828  alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928696682279773"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,9))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930151480907067"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,10))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930567137657722"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,15))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjs/anaconda3/envs/dh/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9005385352775678"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "model_logr = LogisticRegressionCV(cv=5, random_state=11, max_iter=200, n_jobs=-1)\n",
    "model_logr.fit(X_train_counts, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "\n",
    "model_logr.score(X_test_counts, y_test)\n",
    "# 0.89368799245583 << cv=3\n",
    "# 0.8934411962601284 << cv=5\n",
    "# 0.9005385352775678 << counts, ngram_range=(2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7502084778390006"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(1,1))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_logr2 = LogisticRegressionCV(cv=5, random_state=11, max_iter=200, n_jobs=-1)\n",
    "model_logr2.fit(X_train_tfidf, y_train)\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_logr2.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8241330309430472"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(1,2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_logr2 = LogisticRegressionCV(cv=5, random_state=11, max_iter=200, n_jobs=-1)\n",
    "model_logr2.fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_logr2.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#     # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "#     # 'tfidf__use_idf': (True, False),\n",
    "#     # 'tfidf__norm': ('l1', 'l2'),\n",
    "#     'clf__max_iter': (5,),\n",
    "#     'clf__alpha': (0.00001, 0.000001),\n",
    "#     'clf__penalty': ('l2', 'elasticnet'),\n",
    "#     # 'clf__max_iter': (10, 50, 80),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.4 s, sys: 1.41 s, total: 38.8 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mnb_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))),\n",
    "    ('clf', MultinomialNB(alpha=0.001)),\n",
    "])\n",
    "\n",
    "mnb_pipe.fit(X_train.Name, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8927969282966126"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_pipe.score(X_test.Name, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mnb_pipe2 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha=0.001)),\n",
    "])\n",
    "\n",
    "mnb_pipe2.fit(X_train.Name, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pipe2.score(X_test.Name, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.7 s, sys: 1.45 s, total: 40.2 s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnb_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))),\n",
    "    ('clf', ComplementNB(alpha=0.001)),\n",
    "])\n",
    "\n",
    "cnb_pipe.fit(X_train.Name, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8926384591604253"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb_pipe.score(X_test.Name, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.2 s, sys: 1.52 s, total: 47.7 s\n",
      "Wall time: 45.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sgd_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))),\n",
    "    ('clf', SGDClassifier(loss='log', penalty='l2',\n",
    "                          alpha=0.001, random_state=11,\n",
    "                          max_iter=100, tol=1e-3)),\n",
    "])\n",
    "\n",
    "sgd_pipe.fit(X_train.Name, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8472513398435572"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_pipe.score(X_test.Name, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 49s, sys: 3.12 s, total: 17min 52s\n",
      "Wall time: 52min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logrcv_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))),\n",
    "    ('logrCV', LogisticRegressionCV(cv=5, random_state=11, max_iter=1000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe.fit(X_train.Name, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006684280121475"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrcv_pipe.score(X_test.Name, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logrcv_pipe2 = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2,8))),\n",
    "    ('logrCV', LogisticRegressionCV(cv=5, solver='sag', random_state=11, max_iter=1000, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "logrcv_pipe2.fit(X_train.Name, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrcv_pipe2.score(X_test.Name, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 962333  962334  962335 ... 1924662 1924663 1924664] [     0      1      2 ... 962330 962331 962332]\n",
      "[     0      1      2 ... 962330 962331 962332] [ 962333  962334  962335 ... 1924662 1924663 1924664]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(2)\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<384933x83398 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7124730 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848550267189355"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(3,4))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': False, 'use_idf': True}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1539732x27 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9767778 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(1, 1))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "predicted = model_mnb.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6323931697204449"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593269478065013"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(1, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8024929013620552"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(1, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8040516141770127"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', lowercase=False, ngram_range=(2, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7668970963778112"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6359184585369402"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.704418691044935"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977596101139679"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char', lowercase=False, ngram_range=(1, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7042212540883738"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7984922051369978"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwb_vectorizer = CountVectorizer(analyzer='char', lowercase=False, ngram_range=(2, 2))\n",
    "X_train_counts = cwb_vectorizer.fit_transform(X_train.Name)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "model_mnb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_counts = cwb_vectorizer.transform(X_test.Name)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "model_mnb.score(X_test_tfidf, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
